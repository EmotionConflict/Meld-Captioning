{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "f3HaVbc48cLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqoIa5GP8Z75",
        "outputId": "5eeefa67-1b13-4e36-cb1c-eb650374b6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ayr330c8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ayr330c8\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=2747b02443710bc3c280b331feeff5cb65b855c76e9dca87a90e715a5cedb870\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0cp_9lgy/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install transformers accelerate timm torchvision torchaudio pandas tqdm opencv-python\n",
        "!pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import whisper\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
      ],
      "metadata": {
        "id": "8U0uhySO8e5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BLIP-2 for visual captioning\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
        "\n",
        "# Load Whisper for audio transcription\n",
        "whisper_model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "2d76ced4c8c1442da432079d8e74acf0",
            "a97d005b3214437d8274926c4257f1dd",
            "d1732975fa6c4ec8be0bbccde00fcea0",
            "b8bedfb01dae4184ab197a421b3d3961",
            "fda7489ed76145adb70f97e3b84f3264",
            "9d1c6643359e4364944ea29951a3fdd6",
            "f574e2284edd4a12a4e738db70265f48",
            "79597aa6772d4db49911b6757914c12d",
            "df1f92579a6840e5a399d7f49394d17b",
            "7b068000da8e49448ea406e0dae30028",
            "56e3ec76fdae4dadb57e958daedfc974",
            "eacccfc1eccb4157bd9b293fb44db090",
            "2d510419ca354687a2fa51d830bf5718",
            "dc2708d95c174955af220263684205a1",
            "c1dc49ce0b43496f8be32b1ce643e372",
            "02c82ffd61114fa7bca85d7ec446bfcf",
            "31b3562c4e15490ba3f848158c09efca",
            "0ec5e8661d714f508b9ec5b2a2fa8a81",
            "0c57a81bbbf14ef393ec576a02de88b4",
            "698cc3101e2a45de8e7facfdea351cc4",
            "9f8ebaa5cae34d3bae7cee20492c4099",
            "b440e9a1f1fd4a0e96fa6bfd405ac5a9",
            "bc8dcc9030f74084b0662a22f75a7f2e",
            "8d706ccec5fe4ac5892b10c6811d55f2",
            "d1bfd9096ed2494994b570dd22da59b7",
            "25a2b334d1a44148aa5949a8e740a0bb",
            "b76c1176813642a08fb7bbcfc432492f",
            "70c0ad198de74b37bc56cfcfde7296f7",
            "daf2bef06ba14bf79dc09045118a99fc",
            "bbff5dc5e36e4f889bb9250d86a1e49e",
            "8263382907f14cb888ef69e3efa35126",
            "8e634ad21d154f9e8b9689e57c0efd9f",
            "51efb8f6203e484b93e0456664cfd7bd",
            "02383cdebdfd496daa074af2302b066c",
            "4fb25a739ea64cceadbce34ee9fd3079",
            "3a9b7e8abcda402eb5b22b99fd6f7cd4",
            "824b2eb00f0d4324b572b699babe73e6",
            "720b37cee42b43d68d4043250cca7be6",
            "7c014117086f449db4dd97921ef0c003",
            "2053e72829474363a323b29b99b5f1f6",
            "4cdbabbbca8f4e0d85613c1456ef2bf1",
            "4735e18669e54fc28b9f5613556708d2",
            "70c05547233c4cabb99595f9b9797992",
            "3d896c5766f74f0a8efb09b54facac99",
            "44687ae824af4ca6ba2828022b326b6d",
            "70bd507e0b034daa81ba9ef7030355c7",
            "4face1fde0df4c9ca9244509fc8ddd92",
            "74fe1598df674d468882c801ccc48bec",
            "07d3a212eb404d97b63b0199d6902341",
            "cd207c5f78ca4708b4059488d9fd005b",
            "a7d4a99e05ec4f28af1eb8bf0163ad52",
            "e97aa1e0b6394bf5ae5648d482317300",
            "2bb1c0ebcc3240a79131e2c931cf0568",
            "fe70d920c56340acb0e0f8a53937bab7",
            "6b8b31753b0c409b9d34942ed141567f",
            "5a521ae212744de3bf0b9cb477867d0d",
            "f0f4de8611ca482a9bffed6952924474",
            "cf38120ccc7840399701c580c1b0dceb",
            "074c3f627ecf4bb9b0b00e5cfa7de3ec",
            "974fe173368f44e5b0d65326943fd34a",
            "aabc2117933243ceb47cd639eef28736",
            "aab8ba1951e044b3bdc7beee6b60a824",
            "dfe1e04e0cfa4948863f704ea069cd68",
            "927d0b6b350e4f7da264ba85c75a5a9d",
            "4e123e5e6d4d4b6fb312744aaee13cf6",
            "dbbb199403cf418db68852c75ec3e809",
            "873f7b04b4c54392a23b724e73713bae",
            "1c8835e6bbeb47ae961b3a2f90a0e3db",
            "4a82bebaae45496bb3cc4d7d0ff4075b",
            "9054730c1ce64ae0821c6771649773d2",
            "1cacd42dcddc46e39f7dab77145058c2",
            "73c82d2da0514fdeb1798d31a5401046",
            "8acbcadbded442658d6a813125ab8f13",
            "81db17a4e7b84853a0ef20e9ab3d1b60",
            "11511d0db6ab4b2c9cd95002658fb9b6",
            "d8b25b66d2c54471a4d673138e66036d",
            "789ad6237c654f468ac6eb73a84f050d",
            "ffccc93253924dd593c6349ffcfe815f",
            "d81efcc2a40d491f9776f9600cd381f3",
            "31c0de9018854d1dbe9a1eaeeb823968",
            "197675f062934afea32ed8a489fbec7c",
            "03bd7e4f9d3847f8ac813160fbfc2cda",
            "b751129d6fd444f886f21bb0ac2dd610",
            "ba8cf1aece044d58a861281afddcd39c",
            "bec2bcf610264e4293337a29529a5d0f",
            "83b70b11edb549048612e3a7d6b6b064",
            "8474f520f3a44af1a5af1728a45a9316",
            "daebf13acf31496eb1ba231635b9a33f"
          ]
        },
        "id": "LyyBmPzO8gSc",
        "outputId": "27244700-3aba-4960-b2ee-b469e7421297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d76ced4c8c1442da432079d8e74acf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eacccfc1eccb4157bd9b293fb44db090"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc8dcc9030f74084b0662a22f75a7f2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02383cdebdfd496daa074af2302b066c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44687ae824af4ca6ba2828022b326b6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a521ae212744de3bf0b9cb477867d0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "873f7b04b4c54392a23b724e73713bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffccc93253924dd593c6349ffcfe815f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AU Intensity Mapping\n",
        "def map_au_intensity(value):\n",
        "    if value < 0.2:\n",
        "        return \"barely\"\n",
        "    elif value < 1.0:\n",
        "        return \"slightly\"\n",
        "    elif value < 2.5:\n",
        "        return \"moderately\"\n",
        "    elif value < 5.0:\n",
        "        return \"strongly\"\n",
        "    else:\n",
        "        return \"very strongly\"\n",
        "\n",
        "# Loudness Mapping\n",
        "def map_loudness(rms):\n",
        "    if rms < 0.01:\n",
        "        return \"very softly\"\n",
        "    elif rms < 0.03:\n",
        "        return \"softly\"\n",
        "    elif rms < 0.06:\n",
        "        return \"normally\"\n",
        "    elif rms < 0.1:\n",
        "        return \"loudly\"\n",
        "    else:\n",
        "        return \"very loudly\"\n",
        "\n",
        "# AU to facial phrase mapping\n",
        "AU_PHRASES = {\n",
        "    \"AU01\": \"raises the inner eyebrows\",\n",
        "    \"AU02\": \"raises the outer eyebrows\",\n",
        "    \"AU04\": \"furrows the brow\",\n",
        "    \"AU07\": \"tightens the eyelids\",\n",
        "    \"AU12\": \"smiles with mouth corners pulled\",\n",
        "    \"AU15\": \"lowers the mouth corners\",\n",
        "    \"AU17\": \"tightens the chin\",\n",
        "    \"AU25\": \"opens the lips\",\n",
        "    \"AU26\": \"drops the jaw\"\n",
        "}\n",
        "\n",
        "def extract_middle_frame(video_path, save_path):\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        middle_frame = frame_count // 2\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            cv2.imwrite(save_path, frame)\n",
        "        cap.release()\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Could not extract frame from {video_path}: {e}\")\n",
        "\n",
        "def caption_image(image_path):\n",
        "    try:\n",
        "        raw_image = Image.open(image_path).convert('RGB')\n",
        "        inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "        out = blip_model.generate(**inputs)\n",
        "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Visual captioning failed for {image_path}: {e}\")\n",
        "        return \"Visual description unavailable.\"\n",
        "\n",
        "def whisper_transcribe(audio_path):\n",
        "    try:\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return result['text']\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Audio transcription failed for {audio_path}: {e}\")\n",
        "        return \"Audio transcription unavailable.\"\n",
        "\n",
        "def analyze_loudness(audio_path):\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        rms = waveform.pow(2).mean().sqrt().item()\n",
        "        return map_loudness(rms)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Loudness analysis failed for {audio_path}: {e}\")\n",
        "        return \"Unknown loudness.\"\n",
        "\n",
        "def parse_au_intensity(openface_csv_path, peak_index):\n",
        "    try:\n",
        "        df = pd.read_csv(openface_csv_path)\n",
        "        if peak_index >= len(df):\n",
        "            peak_index = len(df) // 2  # fallback to middle if peak invalid\n",
        "        row = df.iloc[peak_index]\n",
        "\n",
        "        au_phrases = []\n",
        "        peak_aus = []\n",
        "\n",
        "        for au in AU_PHRASES.keys():\n",
        "            if f\"{au}_r\" in row:\n",
        "                value = row[f\"{au}_r\"]\n",
        "                if value > 0.1:\n",
        "                    intensity = map_au_intensity(value)\n",
        "                    phrase = AU_PHRASES[au]\n",
        "                    full_phrase = f\"{intensity} {phrase}\"\n",
        "                    au_phrases.append(full_phrase)\n",
        "                    peak_aus.append(au)\n",
        "\n",
        "        return au_phrases, peak_aus\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] AU parsing failed for {openface_csv_path}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "def merge_modalities(visual_phrases, audio_phrase, transcript):\n",
        "    visual_text = \" \".join(visual_phrases)\n",
        "    return (\n",
        "        f\"Visual Description: {visual_text}\\n\"\n",
        "        f\"Audio Description: {audio_phrase}\\n\"\n",
        "        f\"Transcript: \\\"{transcript}\\\"\\n\"\n",
        "        f\"Describe what is happening objectively based on these clues.\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "FJfo43oD8iN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload MELD Data"
      ],
      "metadata": {
        "id": "vW0aoIGW8l9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# After upload, unzip\n",
        "!unzip -q train_video.zip -d train_video\n",
        "!unzip -q train_audio.zip -d train_audio\n",
        "!unzip -q train_subtitles.zip -d train_subtitles\n",
        "!unzip -q openface_outputs.zip -d openface_outputs\n"
      ],
      "metadata": {
        "id": "X6Vv88GI8jls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Labels and Balance Subset"
      ],
      "metadata": {
        "id": "dTd7PVRm8uIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MELD labels\n",
        "df = pd.read_csv('train_labels.csv')\n",
        "\n",
        "# Balanced sample\n",
        "samples_per_emotion = 80\n",
        "balanced_df = df.groupby('Emotion').sample(n=samples_per_emotion, random_state=42)\n",
        "\n",
        "print(balanced_df['Emotion'].value_counts())\n"
      ],
      "metadata": {
        "id": "YIXG8CNq80rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full Batch Cloning"
      ],
      "metadata": {
        "id": "WUw_9JWd8yO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MELD labels\n",
        "df = pd.read_csv('train_labels.csv')\n",
        "\n",
        "# Balanced sample\n",
        "samples_per_emotion = 80\n",
        "balanced_df = df.groupby('Emotion').sample(n=samples_per_emotion, random_state=42)\n",
        "\n",
        "print(balanced_df['Emotion'].value_counts())\n"
      ],
      "metadata": {
        "id": "GDbfDt_M8tU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for idx, row in tqdm(balanced_df.iterrows(), total=len(balanced_df)):\n",
        "    utt_id = row['Utterance_ID']\n",
        "    dia_id = row['Dialogue_ID']\n",
        "\n",
        "    base_name = f\"dia{dia_id}_utt{utt_id}\"\n",
        "    video_path = f\"train_video/{base_name}.mp4\"\n",
        "    audio_path = f\"train_audio/{base_name}.wav\"\n",
        "    subtitle_path = f\"train_subtitles/{base_name}.txt\"\n",
        "    openface_csv_path = f\"openface_outputs/{base_name}.csv\"\n",
        "    frame_path = f\"frame_{base_name}.jpg\"\n",
        "\n",
        "    try:\n",
        "        extract_middle_frame(video_path, frame_path)\n",
        "\n",
        "        visual_caption = caption_image(frame_path)\n",
        "        audio_text = whisper_transcribe(audio_path)\n",
        "        audio_loudness = analyze_loudness(audio_path)\n",
        "\n",
        "        transcript = open(subtitle_path, 'r', encoding='utf-8').read().strip()\n",
        "\n",
        "        df_openface = pd.read_csv(openface_csv_path)\n",
        "        peak_index = df_openface['frame'].idxmax()\n",
        "\n",
        "        visual_prior_list, peak_AU_list = parse_au_intensity(openface_csv_path, peak_index)\n",
        "\n",
        "        merged_caption = merge_modalities(visual_prior_list, audio_loudness, transcript)\n",
        "\n",
        "        sample_id = f\"sample_{idx:08d}\"\n",
        "        results[sample_id] = {\n",
        "            \"AU_list\": list(df_openface.columns[df_openface.columns.str.contains('AU')]),\n",
        "            \"visual_prior_list\": visual_prior_list,\n",
        "            \"audio_prior_list\": audio_loudness,\n",
        "            \"peak_index\": int(peak_index),\n",
        "            \"peak_AU_list\": peak_AU_list,\n",
        "            \"text\": transcript,\n",
        "            \"smp_reason_caption\": merged_caption\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed processing {base_name}: {e}\")\n",
        "\n",
        "# Save output\n",
        "with open('meld_rich_captions.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"Saved {len(results)} samples to meld_rich_captions.json!\")\n"
      ],
      "metadata": {
        "id": "JcxLWb-X8wDB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}